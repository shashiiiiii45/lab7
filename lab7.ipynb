{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707e10dc-68b0-4657-acd4-817294c0301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Randomized Search Results \n",
      "\n",
      "➡ Running LogisticRegression ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression\n",
      "   Best Params : {'model__C': np.float64(0.027825594022071243)}\n",
      "   CV F1       : 0.4790\n",
      "   Test Acc    : 0.5732\n",
      "   Test F1     : 0.5124\n",
      "--------------------------------------------------\n",
      "➡ Running LinearSVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LinearSVM\n",
      "   Best Params : {'model__C': np.float64(0.01)}\n",
      "   CV F1       : 0.4646\n",
      "   Test Acc    : 0.5701\n",
      "   Test F1     : 0.5104\n",
      "--------------------------------------------------\n",
      "➡ Running DecisionTree ...\n",
      "\n",
      "DecisionTree\n",
      "   Best Params : {'model__max_depth': 10}\n",
      "   CV F1       : 0.3860\n",
      "   Test Acc    : 0.4480\n",
      "   Test F1     : 0.3830\n",
      "--------------------------------------------------\n",
      "➡ Running RandomForest ...\n",
      "\n",
      "RandomForest\n",
      "   Best Params : {'model__n_estimators': 200, 'model__max_depth': None}\n",
      "   CV F1       : 0.4044\n",
      "   Test Acc    : 0.5747\n",
      "   Test F1     : 0.4305\n",
      "--------------------------------------------------\n",
      "➡ Running AdaBoost ...\n",
      "\n",
      "AdaBoost\n",
      "   Best Params : {'model__n_estimators': 200}\n",
      "   CV F1       : 0.4210\n",
      "   Test Acc    : 0.5445\n",
      "   Test F1     : 0.4196\n",
      "--------------------------------------------------\n",
      "➡ Running MLP ...\n",
      "\n",
      "MLP\n",
      "   Best Params : {'model__hidden_layer_sizes': (64,), 'model__alpha': 0.0001}\n",
      "   CV F1       : 0.4775\n",
      "   Test Acc    : 0.5400\n",
      "   Test F1     : 0.4736\n",
      "--------------------------------------------------\n",
      "\n",
      " A2 Finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A2_randomized_search_fast.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=[df.columns[-1]])\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Models & parameter grids (SVM replaced with LinearSVC)\n",
    "models = {\n",
    "    \"LogisticRegression\": (LogisticRegression(max_iter=500),\n",
    "        {\"model__C\": np.logspace(-2, 2, 10)}),\n",
    "    \"LinearSVM\": (LinearSVC(max_iter=2000),\n",
    "        {\"model__C\": np.logspace(-2, 2, 5)}),\n",
    "    \"DecisionTree\": (DecisionTreeClassifier(),\n",
    "        {\"model__max_depth\": [3, 5, 10, None]}),\n",
    "    \"RandomForest\": (RandomForestClassifier(),\n",
    "        {\"model__n_estimators\": [100, 200, 400], \"model__max_depth\": [None, 5, 10]}),\n",
    "    \"AdaBoost\": (AdaBoostClassifier(),\n",
    "        {\"model__n_estimators\": [50, 100, 200]}),\n",
    "    \"MLP\": (MLPClassifier(max_iter=500),\n",
    "        {\"model__hidden_layer_sizes\": [(64,), (128,)], \"model__alpha\": [1e-4, 1e-3]})\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"\\n Randomized Search Results \\n\")\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"➡ Running {name} ...\")\n",
    "    pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "    search = RandomizedSearchCV(pipe, params, n_iter=5, cv=cv,\n",
    "                                scoring=\"f1_macro\", random_state=42, n_jobs=-1)\n",
    "    search.fit(X_train, y_train)\n",
    "    y_pred = search.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"   Best Params : {search.best_params_}\")\n",
    "    print(f\"   CV F1       : {search.best_score_:.4f}\")\n",
    "    print(f\"   Test Acc    : {acc:.4f}\")\n",
    "    print(f\"   Test F1     : {f1:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n A2 Finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834170b7-b514-47f9-bf44-4677ca8c0563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Benchmarking Results \n",
      "\n",
      "➡ Running Perceptron ...\n",
      "\n",
      "Perceptron\n",
      "   Accuracy  : 0.5158\n",
      "   Precision : 0.4498\n",
      "   Recall    : 0.4476\n",
      "   F1-score  : 0.4486\n",
      "--------------------------------------------------\n",
      "➡ Running LogisticRegression ...\n",
      "\n",
      "LogisticRegression\n",
      "   Accuracy  : 0.5098\n",
      "   Precision : 0.4458\n",
      "   Recall    : 0.4508\n",
      "   F1-score  : 0.4476\n",
      "--------------------------------------------------\n",
      "➡ Running LinearSVM ...\n",
      "\n",
      "LinearSVM\n",
      "   Accuracy  : 0.5023\n",
      "   Precision : 0.4338\n",
      "   Recall    : 0.4386\n",
      "   F1-score  : 0.4349\n",
      "--------------------------------------------------\n",
      "➡ Running DecisionTree ...\n",
      "\n",
      "DecisionTree\n",
      "   Accuracy  : 0.4389\n",
      "   Precision : 0.3752\n",
      "   Recall    : 0.3767\n",
      "   F1-score  : 0.3750\n",
      "--------------------------------------------------\n",
      "➡ Running RandomForest ...\n",
      "\n",
      "RandomForest\n",
      "   Accuracy  : 0.5792\n",
      "   Precision : 0.6015\n",
      "   Recall    : 0.4398\n",
      "   F1-score  : 0.4380\n",
      "--------------------------------------------------\n",
      "➡ Running AdaBoost ...\n",
      "\n",
      "AdaBoost\n",
      "   Accuracy  : 0.5249\n",
      "   Precision : 0.4670\n",
      "   Recall    : 0.4087\n",
      "   F1-score  : 0.4072\n",
      "--------------------------------------------------\n",
      "➡ Running MLP ...\n",
      "\n",
      "MLP\n",
      "   Accuracy  : 0.5385\n",
      "   Precision : 0.4776\n",
      "   Recall    : 0.4684\n",
      "   F1-score  : 0.4713\n",
      "--------------------------------------------------\n",
      "➡ Running NaiveBayes ...\n",
      "\n",
      "NaiveBayes\n",
      "   Accuracy  : 0.4299\n",
      "   Precision : 0.4376\n",
      "   Recall    : 0.4402\n",
      "   F1-score  : 0.3969\n",
      "--------------------------------------------------\n",
      "\n",
      " A3 Finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A3_classifiers_benchmark_fast.py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=[df.columns[-1]])\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Classifiers (SVM replaced with LinearSVC for speed)\n",
    "models = [\n",
    "    (\"Perceptron\", Perceptron()),\n",
    "    (\"LogisticRegression\", LogisticRegression(max_iter=600)),\n",
    "    (\"LinearSVM\", LinearSVC(max_iter=2000)),\n",
    "    (\"DecisionTree\", DecisionTreeClassifier()),\n",
    "    (\"RandomForest\", RandomForestClassifier()),\n",
    "    (\"AdaBoost\", AdaBoostClassifier()),\n",
    "    (\"MLP\", MLPClassifier(max_iter=600)),\n",
    "    (\"NaiveBayes\", GaussianNB())\n",
    "]\n",
    "\n",
    "print(\"\\n Benchmarking Results \\n\")\n",
    "for name, model in models:\n",
    "    print(f\"➡ Running {name} ...\")\n",
    "    pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"   Accuracy  : {acc:.4f}\")\n",
    "    print(f\"   Precision : {prec:.4f}\")\n",
    "    print(f\"   Recall    : {rec:.4f}\")\n",
    "    print(f\"   F1-score  : {f1:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n A3 Finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f749e8-9fe5-4ace-851e-9308902cfd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
